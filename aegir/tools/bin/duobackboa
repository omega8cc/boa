#!/bin/bash

###
### Acknowledgements
###
### Thomas Sileo @ https://thomassileo.name
### Original recipe: http://bit.ly/1QX462w
###
### Extended by Barracuda Team for BOA project
###
### See also:
### http://www.nongnu.org/duplicity/index.html
###

export HOME=/root
export SHELL=/bin/bash
export PATH=/usr/local/bin:/usr/local/sbin:/opt/local/bin:/usr/bin:/usr/sbin:/bin:/sbin
export _tRee=dev

_CHECK_HOST=$(uname -n 2>&1)

_check_root() {
  if [ `whoami` = "root" ]; then
    ionice -c2 -n7 -p $$
    renice 19 -p $$
    chmod a+w /dev/null
    [ -e "/root/.gnupg" ] && chmod 700 /root/.gnupg
  else
    echo "ERROR: This script should be run as a root user"
    exit 1
  fi
  _DF_TEST=$(df -kTh / -l \
    | grep '/' \
    | sed 's/\%//g' \
    | awk '{print $6}' 2> /dev/null)
  _DF_TEST=${_DF_TEST//[^0-9]/}
  if [ ! -z "${_DF_TEST}" ] && [ "${_DF_TEST}" -gt "90" ]; then
    echo "ERROR: Your disk space is almost full !!! ${_DF_TEST}/100"
    echo "ERROR: We can not proceed until it is below 90/100"
    exit 1
  fi
}
_check_root

if [ -e "/root/.pause_heavy_tasks_maint.cnf" ]; then
  exit 0
fi

# New OpenSSL 3.x version is required
if [ ! -x "/usr/local/ssl3/bin/openssl" ]; then
  echo "New OpenSSL 3.x version is required"
  exit 1
fi

_PTN_VRN=3.12.5
_DCY_VRN=3.0.2
_LOGPTH="/var/xdrago/log"
_NOW=$(date +%y%m%d-%H%M%S 2>&1)
_NOW=${_NOW//[^0-9-]/}
_DOW=$(date +%u 2>&1)
_DOW=${_DOW//[^1-7]/}
_DOM=$(date +%e 2>&1)
_DOM=${_DOM//[^0-9]/}
_HST=$(uname -n 2>&1)
_HST=${_HST//[^a-zA-Z0-9-.]/}
_HST=$(echo -n ${_HST} | tr A-Z a-z 2>&1)
_HST_DASH=$(echo -n ${_HST} | tr . - 2>&1)

_crlGet="-L --max-redirs 3 -k -s --retry 3 --retry-delay 5 -A iCab"
_aptYesUnth="-y --allow-unauthenticated"

[ -e "/root/.duobackboa.cnf" ] && source /root/.duobackboa.cnf

export _INCIDENT_EMAIL_REPORT=${_INCIDENT_EMAIL_REPORT//[^A-Z]/}
: "${_INCIDENT_EMAIL_REPORT:=YES}"

_AWS_VLV=${_AWS_VLV//[^a-z]/}
if [ -z "${_AWS_VLV}" ]; then
  _AWS_VLV="warning"
fi

# Set extra environment variables
export PYTHONPATH="/usr/local/lib/python3.12/site-packages"

_DCY_PTN="/usr/local/bin/python3"
_DCY_CMD="/usr/local/bin/duplicity -v ${_AWS_VLV}"

if [ "$1" != "help" ]; then
  # Check the Python version to ensure we're using the correct one
  echo "Checking expected Python ${_PTN_VRN} version..."
  ${_DCY_PTN} --version
  # Check the Duplicity version to ensure we're using the correct one
  echo "Checking expected Duplicity ${_DCY_VRN} version..."
  ${_DCY_CMD} --version
fi

_os_detection_minimal() {
  _APT_UPDATE="apt-get update"
  _OS_CODE=$(lsb_release -ar 2>/dev/null | grep -i codename | cut -s -f2 2>&1)
  _OS_LIST="daedalus chimaera beowulf buster bullseye bookworm"
  for e in ${_OS_LIST}; do
    if [ "${e}" = "${_OS_CODE}" ]; then
      _APT_UPDATE="apt-get update --allow-releaseinfo-change"
    fi
  done
}
_os_detection_minimal

_apt_clean_update() {
  #apt-get clean -qq 2> /dev/null
  #rm -rf /var/lib/apt/lists/* &> /dev/null
  ${_APT_UPDATE} -qq 2> /dev/null
}

_if_hosted_sys() {
  if [ -e "/root/.host8.cnf" ] \
    || [[ "${_CHECK_HOST}" =~ ".aegir.cc"($) ]]; then
    _hostedSys=YES
  else
    _hostedSys=NO
  fi
}
_if_hosted_sys

_check_vps() {
  _BENG_VS=NO
  _VM_TEST=$(uname -a 2>&1)
  if [[ "${_VM_TEST}" =~ "-beng" ]]; then
    _BENG_VS=YES
  fi
}
_check_vps

_find_fast_mirror_early() {
  _isNetc=$(which netcat 2>&1)
  if [ ! -x "${_isNetc}" ] || [ -z "${_isNetc}" ]; then
    if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
      && [ -e "/etc/apt/apt.conf.d" ]; then
      echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
    fi
    _apt_clean_update
    apt-get install netcat ${_aptYesUnth}
    apt-get install netcat-traditional ${_aptYesUnth}
    wait
  fi
  _ffMirr=$(which ffmirror 2>&1)
  if [ -x "${_ffMirr}" ]; then
    _ffList="/var/backups/boa-mirrors-2024-01.txt"
    mkdir -p /var/backups
    if [ ! -e "${_ffList}" ]; then
      echo "de.files.aegir.cc"  > ${_ffList}
      echo "ny.files.aegir.cc" >> ${_ffList}
      echo "sg.files.aegir.cc" >> ${_ffList}
    fi
    if [ -e "${_ffList}" ]; then
      _BROKEN_FFMIRR_TEST=$(grep "stuff" ${_ffMirr} 2>&1)
      if [[ "${_BROKEN_FFMIRR_TEST}" =~ "stuff" ]]; then
        _CHECK_MIRROR=$(bash ${_ffMirr} < ${_ffList} 2>&1)
        _USE_MIR="${_CHECK_MIRROR}"
        [[ "${_USE_MIR}" =~ "printf" ]] && _USE_MIR="files.aegir.cc"
      else
        _USE_MIR="files.aegir.cc"
      fi
    else
      _USE_MIR="files.aegir.cc"
    fi
  else
    _USE_MIR="files.aegir.cc"
  fi
  _urlDev="http://${_USE_MIR}/dev"
  _urlHmr="http://${_USE_MIR}/versions/${_tRee}/boa/aegir"
}

_install() {
  if [ ! -d "${_LOGPTH}" ]; then
    mkdir -p ${_LOGPTH}
  fi
  [ -e "/root/.gnupg" ] && chmod 700 /root/.gnupg
  _DUPLICITY_ITD=$(duplicity --version 2>&1 \
    | tr -d "\n" \
    | cut -d" " -f2 \
    | awk '{ print $1}' 2>&1)
  if [ "${_DUPLICITY_ITD}" = "${_DCY_VRN}" ] \
    && [ -L "/usr/local/bin/jp.py" ] \
    && [ -L "/usr/local/bin/duplicity" ] \
    && [ -L "/usr/local/bin/aws" ]; then
    echo "Latest duplicity version ${_DCY_VRN} already installed"
  else
    echo "Installing duplicity dependencies..."
    cd
    _find_fast_mirror_early
    if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
      && [ -e "/etc/apt/apt.conf.d" ]; then
      echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
    fi
    _apt_clean_update
    aptitude purge duplicity -y
    rm -f /usr/local/bin/duplicity
    rm -f /usr/local/bin/jp.py
    rm -f /usr/local/bin/aws*
    apt-get install -y \
        intltool \
        libffi-dev \
        par2 \
        python3-pip \
        python3-venv \
        python3 \
        rclone \
        rdiff \
        tzdata
    _PTN_TEST=$(${_DCY_PTN} --version 2>&1)
    if [[ ! "${_PTN_TEST}" =~ "Python ${_PTN_VRN}" ]] \
      || [ ! -x "${_DCY_PTN}" ]; then
      cd /var/opt
      rm -rf Python*
      wget -q -U iCab ${_urlDev}/src/Python-${_PTN_VRN}.tgz
      tar -xzf Python-${_PTN_VRN}.tgz
      cd Python-${_PTN_VRN}
      if [ -d "/usr/local/ssl3" ]; then
        bash ./configure --with-openssl=/usr/local/ssl3
      else
        bash ./configure --with-openssl=/usr/local/ssl
      fi
      make -j $(nproc) --quiet
      make install --quiet
      cd
    fi
    _PTN_TEST=$(${_DCY_PTN} --version 2>&1)
    if [[ "${_PTN_TEST}" =~ "Python ${_PTN_VRN}" ]]; then
      python3 -m pip install pipx --break-system-packages --root-user-action ignore
      pip3 install --upgrade pip --root-user-action ignore
      export PIPX_BIN_DIR=/usr/local/bin
      export PIPX_HOME=/opt/pipx/venvs
      pipx install duplicity --include-deps --force
      pipx install awscli --include-deps --force
      pipx install boto3 --include-deps --force
    else
      echo "Python ${_PTN_VRN} installation failed with ${_PTN_TEST}"
      exit 1
    fi
    _DCY_TEST=$(${_DCY_CMD} --version 2>&1)
    if [[ "${_DCY_TEST}" =~ "duplicity ${_DCY_VRN}" ]]; then
      echo "Installation complete!"
    else
      echo "Installation failed with ${_DCY_TEST}"
      exit 1
    fi
  fi
}

_check_aws() {
  if [ ! -x "/usr/local/bin/aws" ]; then
    echo "Upgrade to add AWS tools required..."
    install
  fi
}

if [ `ps aux | grep -v "grep" | grep --count "duplicity"` -gt "0" ]; then
  echo "The duplicity backup is already running!"
  echo "Active duplicity process detected..."
  exit 1
fi

if [ -z "${_AWS_KEY}" ] || [ -z "${_AWS_SEC}" ] || [ -z "${_AWS_PWD}" ]; then
  echo "

  CONFIGURATION REQUIRED!

  Add listed below four (4) required lines to your /root/.duobackboa.cnf file.
  Required lines are marked with [R] and optional with [O]:

    _AWS_KEY='Your AWS Access Key ID'     ### [R] From your AWS S3 settings
    _AWS_SEC='Your AWS Secret Access Key' ### [R] From your AWS S3 settings
    _AWS_PWD='Your Secret Password'       ### [R] Generate with 'openssl rand -base64 32'
    _AWS_REG='Your AWS Region ID'         ### [R] By default 'us-east-1'

    _AWS_TTL='Your Backup Rotation'       ### [O] By default '30D'
    _AWS_FLC='Your Backup Full Cycle'     ### [O] By default '7D'
    _AWS_VLV='Your Backup Log Verbosity'  ### [O] By default 'warning' -- [ewnid]
    _AWS_EXB='Exclude Aegir Backups'      ### [O] By default 'YES' -- can be YES/NO

    Supported values to use as _AWS_REG (the symbol after the # comment):

      Africa (Cape Town)         # af-south-1
      Asia Pacific (Hong Kong)   # ap-east-1
      Asia Pacific (Hyderabad)   # ap-south-2
      Asia Pacific (Jakarta)     # ap-southeast-3
      Asia Pacific (Melbourne)   # ap-southeast-4
      Asia Pacific (Mumbai)      # ap-south-1
      Asia Pacific (Osaka)       # ap-northeast-3
      Asia Pacific (Seoul)       # ap-northeast-2
      Asia Pacific (Singapore)   # ap-southeast-1
      Asia Pacific (Sydney)      # ap-southeast-2
      Asia Pacific (Tokyo)       # ap-northeast-1
      Canada (Central)           # ca-central-1
      Canada West (Calgary)      # ca-west-1
      Europe (Frankfurt)         # eu-central-1
      Europe (Ireland)           # eu-west-1
      Europe (London)            # eu-west-2
      Europe (Milan)             # eu-south-1
      Europe (Paris)             # eu-west-3
      Europe (Spain)             # eu-south-2
      Europe (Stockholm)         # eu-north-1
      Europe (Zurich)            # eu-central-2
      Israel (Tel Aviv)          # il-central-1
      Middle East (Bahrain)      # me-south-1
      Middle East (UAE)          # me-central-1
      South America (SÃ£o Paulo)  # sa-east-1
      US East (N. Virginia)      # us-east-1
      US East (Ohio)             # us-east-2
      US West (N. California)    # us-west-1
      US West (Oregon)           # us-west-2

      ### Special regions, see: https://aws.amazon.com/govcloud-us/

      AWS GovCloud (US-East)     # us-gov-east-1
      AWS GovCloud (US-West)     # us-gov-west-1

    Source: http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region

    You have to use S3 Console at https://console.aws.amazon.com/s3/home
    (before attempting to run initial backup!) to create S3 bucket in the
    desired region with correct name as shown below:

      daily-remote-${_HST_DASH}

    While duplicity should be able to create new bucket on demand, in practice
    it almost never works due to typical delays between various AWS regions.

    Please run: 'duobackboa test' to make sure that the connection works.

  "
  exit 1
fi

if [ -z "${_AWS_REG}" ]; then
  _AWS_REG="us-east-1"
fi

if [ "${_AWS_REG}" = "af-south-1" ] \
  || [ "${_AWS_REG}" = "ap-east-1" ] \
  || [ "${_AWS_REG}" = "ap-northeast-1" ] \
  || [ "${_AWS_REG}" = "ap-northeast-2" ] \
  || [ "${_AWS_REG}" = "ap-northeast-3" ] \
  || [ "${_AWS_REG}" = "ap-south-1" ] \
  || [ "${_AWS_REG}" = "ap-south-2" ] \
  || [ "${_AWS_REG}" = "ap-southeast-1" ] \
  || [ "${_AWS_REG}" = "ap-southeast-2" ] \
  || [ "${_AWS_REG}" = "ap-southeast-3" ] \
  || [ "${_AWS_REG}" = "ap-southeast-4" ] \
  || [ "${_AWS_REG}" = "ca-central-1" ] \
  || [ "${_AWS_REG}" = "ca-west-1" ] \
  || [ "${_AWS_REG}" = "eu-central-1" ] \
  || [ "${_AWS_REG}" = "eu-central-2" ] \
  || [ "${_AWS_REG}" = "eu-north-1" ] \
  || [ "${_AWS_REG}" = "eu-south-1" ] \
  || [ "${_AWS_REG}" = "eu-south-2" ] \
  || [ "${_AWS_REG}" = "eu-west-1" ] \
  || [ "${_AWS_REG}" = "eu-west-2" ] \
  || [ "${_AWS_REG}" = "eu-west-3" ] \
  || [ "${_AWS_REG}" = "il-central-1" ] \
  || [ "${_AWS_REG}" = "me-central-1" ] \
  || [ "${_AWS_REG}" = "me-south-1" ] \
  || [ "${_AWS_REG}" = "sa-east-1" ] \
  || [ "${_AWS_REG}" = "us-east-1" ] \
  || [ "${_AWS_REG}" = "us-east-2" ] \
  || [ "${_AWS_REG}" = "us-west-1" ] \
  || [ "${_AWS_REG}" = "us-west-2" ] \
  || [ "${_AWS_REG}" = "us-gov-east-1" ] \
  || [ "${_AWS_REG}" = "us-gov-west-1" ]; then
  _GOOD_AWS_REG=YES
fi

_AWS_TTL=${_AWS_TTL//[^A-Z0-9]/}
if [ -z "${_AWS_TTL}" ]; then
  _AWS_TTL="30D"
fi

_AWS_FLC=${_AWS_FLC//[^A-Z0-9]/}
if [ -z "${_AWS_FLC}" ]; then
  _AWS_FLC="7D"
fi

if [ "${_hostedSys}" = "YES" ] \
  && [ -e "/var/xdrago" ]; then
  _AWS_FLC="14D"
fi

if [ ! -z "${_AWS_EXB}" ] && [ "${_AWS_EXB}" = "NO" ]; then
  _EXCLUDE="--exclude /data/conf/arch"
else
  _EXCLUDE="--exclude /data/conf/arch --exclude-regexp '^/data/disk/.*/backups/'"
fi

_USER_INCLUDE=""
if [ -f "/root/.duobackboa.include" ]; then
  _USER_INCLUDE="--include-filelist /root/.duobackboa.include"
fi

_USER_EXCLUDE=""
if [ -f "/root/.duobackboa.exclude" ]; then
  _USER_EXCLUDE="--exclude-filelist /root/.duobackboa.exclude"
fi

export AWS_ACCESS_KEY_ID="${_AWS_KEY}"
export AWS_SECRET_ACCESS_KEY="${_AWS_SEC}"
export PASSPHRASE="${_AWS_PWD}"

_SOURCE="/etc /var/aegir /var/www /home /data"
_BUCKET="daily-remote-${_HST_DASH}"
_BUCKET_DOT="daily.remote.${_HST}"
_TARGET="boto3+s3://${_BUCKET}"
_LOGFILE="${_LOGPTH}/${_BUCKET}.log"
_NAME="--name=daily-remote"

_DCY_MN_CMD="/usr/local/bin/duplicity -v ${_AWS_VLV} \
  --concurrency 4 \
  --s3-endpoint-url https://s3.dualstack.${_AWS_REG}.amazonaws.com \
  --s3-region-name ${_AWS_REG}"

if [ -e "${_LOGPTH}/${_BUCKET_DOT}.archive.log" ]; then
  cat ${_LOGPTH}/${_BUCKET_DOT}.archive.log >> ${_LOGPTH}/${_BUCKET}.archive.log
  mv ${_LOGPTH}/${_BUCKET_DOT}.archive.log /var/backups/${_BUCKET_DOT}.archive.log
  cat ${_LOGPTH}/${_BUCKET_DOT}.randomize.cleanup.log >> ${_LOGPTH}/${_BUCKET}.randomize.cleanup.log
  mv ${_LOGPTH}/${_BUCKET_DOT}.randomize.cleanup.log /var/backups/${_BUCKET_DOT}.randomize.cleanup.log
  #apt-get clean -qq
  #rm -rf /var/lib/apt/lists/*
  if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
    && [ -e "/etc/apt/apt.conf.d" ]; then
    echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
  fi
  aws s3 mb s3://${_BUCKET} --region ${_AWS_REG}
  aws s3 sync s3://${_BUCKET_DOT} s3://${_BUCKET}
fi

_backup_prepare() {
  _INCLUDE=""
  for _CDIR in ${_SOURCE}; do
    TMP=" --include  ${_CDIR}"
    _INCLUDE="${_INCLUDE}${TMP}"
  done
  if [ -e "/root/.cache/duplicity" ]; then
    _CacheTest=$(find /root/.cache/duplicity/* \
      -maxdepth 1 \
      -mindepth 1 \
      -type f \
      | sort 2>&1)
    if [[ "${_CacheTest}" =~ "No such file or directory" ]] \
      || [ -z "${_CacheTest}" ]; then
      _DO_CLEANUP=NO
    else
      _DO_CLEANUP=YES
    fi
  fi
}

_monthly_cleanup() {
  if [ -e "${_LOGPTH}/${_BUCKET}.randomize.cleanup.log" ]; then
    _RCL=$(cat ${_LOGPTH}/${_BUCKET}.randomize.cleanup.log 2>&1)
    _RCL=$(echo -n ${_RCL} | tr -d "\n" 2>&1)
    _RCL=${_RCL//[^1-5]/}
  else
    _RCL=$((RANDOM%5+1))
    _RCL=${_RCL//[^1-5]/}
    echo ${_RCL} > ${_LOGPTH}/${_BUCKET}.randomize.cleanup.log
  fi
  if [ -e "${_LOGPTH}/${_BUCKET}.archive.log" ] \
    && [ ! -e "/root/.skip_duplicity_monthly_cleanup.cnf" ] \
    && [ "${_DOM}" = "${_RCL}" ] \
    && [ "${_DO_CLEANUP}" = "YES" ]; then
    if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
      _n=$((RANDOM%300+8))
      echo "Waiting $n seconds on `date` before running cleanup --force" > ${_LOGFILE}
      sleep ${_n}
    fi
    echo "Running cleanup --force on `date`" >> ${_LOGFILE}
    echo "Command is ${_DCY_MN_CMD} cleanup --force ${_NAME} ${_TARGET}"
    ${_DCY_MN_CMD} cleanup --force ${_NAME} ${_TARGET}
    rm -f ${_LOGPTH}/${_BUCKET}.randomize.full.log
    rm -f ${_LOGPTH}/${_BUCKET}.randomize.cleanup.log
  fi
}

_randomize_full() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    if [ -e "${_LOGPTH}/${_BUCKET}.randomize.full.log" ]; then
      _RDW=$(cat ${_LOGPTH}/${_BUCKET}.randomize.full.log 2>&1)
      _RDW=$(echo -n ${_RDW} | tr -d "\n" 2>&1)
      _RDW=${_RDW//[^1-7]/}
      _MODE="incremental"
    else
      _RDW=$((RANDOM%7+1))
      _RDW=${_RDW//[^1-7]/}
      _MODE="full"
      echo ${_RDW} > ${_LOGPTH}/${_BUCKET}.randomize.full.log
    fi
  else
    _RDW=6
  fi
}

_set_mode() {
  if [ "${_DOW}" = "${_RDW}" ] && [ "${_AWS_FLC}" = "7D" ]; then
    if [ ! -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
      _MODE="full"
      _AWS_FLC="1M"
    fi
  else
    if [ -e "${_LOGPTH}/${_BUCKET}.archive.log" ] \
      && [ "${_DO_CLEANUP}" = "YES" ]; then
      _MODE="incremental"
    else
      _MODE="full"
    fi
  fi
}

_set_cmd() {
  _DCY_UP_CMD="/usr/local/bin/duplicity ${_MODE} -v ${_AWS_VLV} \
    --allow-source-mismatch \
    --concurrency 4 \
    --full-if-older-than ${_AWS_FLC} \
    --s3-endpoint-url https://s3.dualstack.${_AWS_REG}.amazonaws.com \
    --s3-region-name ${_AWS_REG} \
    --s3-use-ia \
    --volsize 300"
}

_run_backup() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    if [ ! -e "/root/tmp/home/" ]; then
      _n=$((RANDOM%300+8))
      echo "Waiting $n seconds on `date` before running restore home 7D tmp/home" >> ${_LOGFILE}
      sleep ${_n}
      restore home 7D tmp/home >> ${_LOGFILE}
    fi
    _n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running ${_MODE} backup" >> ${_LOGFILE}
    sleep ${_n}
  fi
  echo "Running ${_MODE} backup on `date`" >> ${_LOGFILE}
  echo "Command is ${_DCY_UP_CMD} \
    ${_NAME} \
    ${_EXCLUDE} \
    ${_USER_EXCLUDE} \
    ${_INCLUDE} \
    ${_USER_INCLUDE} \
    --exclude '**' / ${_TARGET}"
  ${_DCY_UP_CMD} \
    ${_NAME} \
    ${_EXCLUDE} \
    ${_USER_EXCLUDE} \
    ${_INCLUDE} \
    ${_USER_INCLUDE} \
    --exclude '**' / ${_TARGET} >> ${_LOGFILE}
}

_remove_older_than() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    _n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running remove-older-than ${_AWS_TTL}" >> ${_LOGFILE}
    sleep ${_n}
  fi
  echo "Running remove-older-than on `date`" >> ${_LOGFILE}
  echo "Command is ${_DCY_MN_CMD} remove-older-than ${_AWS_TTL} --force ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} remove-older-than ${_AWS_TTL} --force ${_NAME} ${_TARGET} >> ${_LOGFILE}
}

_collection_status() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    _n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running collection-status" >> ${_LOGFILE}
    sleep ${_n}
  fi
  echo "Running collection-status on `date`" >> ${_LOGFILE}
  echo "Command is ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET} >> ${_LOGFILE}
}

_backup() {
  _backup_prepare
  _monthly_cleanup
  _randomize_full
  _set_mode
  _set_cmd
  _run_backup
  if [ -e "${_LOGPTH}/${_BUCKET}.archive.log" ] \
    && [ "${_DOW}" = "${_RDW}" ] \
    && [ "${_DO_CLEANUP}" = "YES" ]; then
    _remove_older_than
    _collection_status
  fi
  if [ -n "${_MY_EMAIL}" ] && [ "${_INCIDENT_EMAIL_REPORT}" = "YES" ]; then
    echo "Sending email report on `date`" >> ${_LOGFILE}
    s-nail -s "Daily backup: ${_MODE} ${_HST} $(date 2>&1)" ${_MY_EMAIL} < ${_LOGFILE}
  fi
  cat ${_LOGFILE} >> ${_LOGPTH}/${_BUCKET}.archive.log
  rm -f ${_LOGFILE}
}

_conn_test() {
  if [ $# = 1 ]; then
    _BUCKET="daily-remote-$1"
    _TARGET="boto3+s3://${_BUCKET}"
  fi
  echo "Running AWS connection test, please wait..."
  echo "Command is ${_DCY_MN_CMD} cleanup --dry-run --timeout 5 ${_NAME} ${_TARGET}"
  _ConnTest=$(${_DCY_MN_CMD} cleanup --dry-run --timeout 5 ${_NAME} ${_TARGET} 2>&1)
  ### echo _ConnTest is STR ${_ConnTest} END
  if [[ "${_ConnTest}" =~ "No connection to backend" ]] \
    || [[ "${_ConnTest}" =~ "IllegalLocationConstraintException" ]]; then
    echo
    echo "  Sorry, I can't connect to ${_TARGET}"
    echo "  Please check if the bucket has expected name: ${_BUCKET}"
    echo "  This bucket must already exist in the ${_AWS_REG} AWS region"
    echo "  http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region"
    echo "  Bye"
    echo
    exit 1
  else
    echo "OK, I can connect to ${_TARGET}"
  fi
}

_status() {
  echo "Command is ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET}
}

_cleanup() {
  echo "Command is ${_DCY_MN_CMD} cleanup --force ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} cleanup --force ${_NAME} ${_TARGET}
  echo "Command is ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} collection-status ${_NAME} ${_TARGET}
}

_list() {
  echo "Command is ${_DCY_MN_CMD} list-current-files ${_NAME} ${_TARGET}"
  ${_DCY_MN_CMD} list-current-files ${_NAME} ${_TARGET}
}

_restore() {
  if [ $# = 2 ]; then
    echo "Command is ${_DCY_MN_CMD} restore --file-to-restore $1 ${_NAME} ${_TARGET} $2"
    ${_DCY_MN_CMD} restore --file-to-restore $1 ${_NAME} ${_TARGET} $2
  else
    echo "Command is ${_DCY_MN_CMD} restore --file-to-restore $1 --time $2 ${_NAME} ${_TARGET} $3"
    ${_DCY_MN_CMD} restore --file-to-restore $1 --time $2 ${_NAME} ${_TARGET} $3
  fi
}

_retrieve() {
  if [ $# = 3 ]; then
    _HST_DASH=$(echo -n $3 | tr . - 2>&1)
    _BUCKET="daily-remote-${_HST_DASH}"
    _TARGET="boto3+s3://${_BUCKET}"
    echo "Command is ${_DCY_MN_CMD} restore --file-to-restore $1 ${_NAME} ${_TARGET} $2"
    ${_DCY_MN_CMD} restore --file-to-restore $1 ${_NAME} ${_TARGET} $2
  elif [ $# = 4 ]; then
    _HST_DASH=$(echo -n $4 | tr . - 2>&1)
    _BUCKET="daily-remote-${_HST_DASH}"
    _TARGET="boto3+s3://${_BUCKET}"
    echo "Command is ${_DCY_MN_CMD} restore --file-to-restore $1 --time $2 ${_NAME} ${_TARGET} $3"
    ${_DCY_MN_CMD} restore --file-to-restore $1 --time $2 ${_NAME} ${_TARGET} $3
  fi
}

if [ "$1" = "backup" ]; then
  if test -f /run/${_HST}_backup.pid ; then
    touch ${_LOGPTH}/wait_${_HST}_backup.log
    echo "The duplicity backup is running already?"
    echo "Existing /run/${_HST}_backup.pid found..."
    echo "But no active duplicity process detected..."
    exit 1
  else
    touch /run/${_HST}_backup.pid
    echo "The duplicity backup is starting now..."
    _check_aws
    _backup
    echo "The duplicity backup is complete!"
    touch ${_LOGPTH}/run_${_HST}_backup.log
    rm -f /run/${_HST}_backup.pid
  fi
elif [ "$1" = "install" ]; then
  _install
elif [ "$1" = "cleanup" ]; then
  _cleanup
elif [ "$1" = "list" ]; then
  _list
elif [ "$1" = "restore" ]; then
  if [ $# = 3 ]; then
    _restore $2 $3
  else
    _restore $2 $3 $4
  fi
elif [ "$1" = "retrieve" ]; then
  if [ $# = 4 ]; then
    _retrieve $2 $3 $4
  elif [ $# = 5 ]; then
    _retrieve $2 $3 $4 $5
  else
    echo "You have to specify also hostname of the backed up system"
    exit 1
  fi
elif [ "$1" = "status" ]; then
  _check_aws
  _status
elif [ "$1" = "test" ]; then
  _conn_test
else
  echo "

  INSTALLATION:

  $ duobackboa install

  USAGE:

  $ duobackboa backup
  $ duobackboa cleanup
  $ duobackboa list
  $ duobackboa status
  $ duobackboa test
  $ duobackboa restore file [time] destination
  $ duobackboa retrieve file [time] destination hostname

  RESTORE EXAMPLES:

  Note: Be careful while restoring not to prepend a slash to the path!

  Restoring a single file to tmp/
  $ duobackboa restore data/disk/o1/backups/foo.tar.gz tmp/foo.tar.gz

  Restoring an older version of a directory to tmp/ - interval or full date
  $ duobackboa restore data/disk/o1/backups 7D8h8s tmp/backups
  $ duobackboa restore data/disk/o1/backups 2014/11/11 tmp/backups

  Restoring data on a different server
  $ duobackboa retrieve data/disk/o1/backups/foo.tar.gz tmp/foo.tar.gz srv.foo.bar
  $ duobackboa retrieve data/disk/o1/backups 2014/11/11 tmp/backups srv.foo.bar

  Note: The srv.foo.bar is a hostname of the BOA system backed up before.
        In the 'retrieve' mode it will use the _AWS_* variables configured
        in the current system /root/.duobackboa.cnf file - so make sure to edit
        this file to set/replace temporarily all four required _AWS_* variables
        used originally on the host you are retrieving data from! You should
        keep them secret and manage in your offline password manager app.

  "
  exit 1
fi

export AWS_ACCESS_KEY_ID=
export AWS_SECRET_ACCESS_KEY=
export PASSPHRASE=

exit 0
