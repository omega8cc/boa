#!/bin/bash

###
### Acknowledgements
###
### Thomas Sileo @ https://thomassileo.name
### Original recipe: http://bit.ly/1QX462w
###
### Extended by Barracuda Team for BOA project
###
### See also:
### http://www.nongnu.org/duplicity/index.html
###

HOME=/root
SHELL=/bin/bash
PATH=/usr/local/bin:/usr/local/sbin:/opt/local/bin:/usr/bin:/usr/sbin:/bin:/sbin

export PATH=${PATH}
export SHELL=${SHELL}
export HOME=${HOME}

_DUPLICITY_VRN="0.7.19"
_BOTO_VRN="2.49.0"
_FASTENERS_VRN="0.14.1"
_LOGPTH="/var/xdrago/log"
_NOW=$(date +%y%m%d-%H%M%S 2>&1)
_NOW=${_NOW//[^0-9-]/}
_DOW=$(date +%u 2>&1)
_DOW=${_DOW//[^1-7]/}
_DOM=$(date +%e 2>&1)
_DOM=${_DOM//[^0-9]/}
_HST=$(uname -n 2>&1)
_HST=${_HST//[^a-zA-Z0-9-.]/}
_HST=$(echo -n ${_HST} | tr A-Z a-z 2>&1)
_HST_DASH=$(echo -n ${_HST} | tr . - 2>&1)

crlGet="-L --max-redirs 10 -k -s --retry 10 --retry-delay 5 -A iCab"
aptYesUnth="-y --allow-unauthenticated"
tRee=dev
export tRee="${tRee}"

check_root() {
  if [ `whoami` = "root" ]; then
    ionice -c2 -n7 -p $$
    renice 19 -p $$
    chmod a+w /dev/null
    if [ ! -e "/dev/fd" ]; then
      if [ -e "/proc/self/fd" ]; then
        rm -rf /dev/fd
        ln -s /proc/self/fd /dev/fd
      fi
    fi
  else
    echo "ERROR: This script should be ran as a root user"
    exit 1
  fi
  _DF_TEST=$(df -kTh / -l \
    | grep '/' \
    | sed 's/\%//g' \
    | awk '{print $6}' 2> /dev/null)
  _DF_TEST=${_DF_TEST//[^0-9]/}
  if [ ! -z "${_DF_TEST}" ] && [ "${_DF_TEST}" -gt "90" ]; then
    echo "ERROR: Your disk space is almost full !!! ${_DF_TEST}/100"
    echo "ERROR: We can not proceed until it is below 90/100"
    exit 1
  fi
}
check_root

if [ -e "/root/.pause_heavy_tasks_maint.cnf" ]; then
  exit 0
fi

os_detection_minimal() {
  _APT_UPDATE="apt-get update"
  _THIS_RV=$(lsb_release -ar 2>/dev/null | grep -i codename | cut -s -f2 2>&1)
  _OS_LIST="daedalus chimaera beowulf buster bullseye bookworm"
  for e in ${_OS_LIST}; do
    if [ "${e}" = "${_THIS_RV}" ]; then
      _APT_UPDATE="apt-get update --allow-releaseinfo-change"
    fi
  done
}
os_detection_minimal

apt_clean_update() {
  #apt-get clean -qq 2> /dev/null
  #rm -rf /var/lib/apt/lists/* &> /dev/null
  ${_APT_UPDATE} -qq 2> /dev/null
}

check_vps() {
  _BENG_VS=NO
  _VMFAMILY=NO
  _CHECK_HOST=$(uname -n 2>&1)
  _VM_TEST=$(uname -a 2>&1)
  if [[ "${_VM_TEST}" =~ "-beng" ]]; then
    _BENG_VS=YES
  fi
  if [[ "${_CHECK_HOST}" =~ ".host8." ]] \
    || [[ "${_CHECK_HOST}" =~ ".boa.io"($) ]] \
    || [[ "${_CHECK_HOST}" =~ ".o8.io"($) ]] \
    || [[ "${_CHECK_HOST}" =~ ".aegir.cc"($) ]]; then
    _VMFAMILY=HOSTED
  fi
}
check_vps

find_fast_mirror_early() {
  isNetc=$(which netcat 2>&1)
  if [ ! -x "${isNetc}" ] || [ -z "${isNetc}" ]; then
    if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
      && [ -e "/etc/apt/apt.conf.d" ]; then
      echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
    fi
    apt_clean_update
    apt-get install netcat ${aptYesUnth}
    apt-get install netcat-traditional ${aptYesUnth}
    wait
  fi
  ffMirr=$(which ffmirror 2>&1)
  if [ -x "${ffMirr}" ]; then
    ffList="/var/backups/boa-mirrors-2024-01.txt"
    mkdir -p /var/backups
    if [ ! -e "${ffList}" ]; then
      echo "de.files.aegir.cc"  > ${ffList}
      echo "ny.files.aegir.cc" >> ${ffList}
      echo "sg.files.aegir.cc" >> ${ffList}
    fi
    if [ -e "${ffList}" ]; then
      _BROKEN_FFMIRR_TEST=$(grep "stuff" ${ffMirr} 2>&1)
      if [[ "${_BROKEN_FFMIRR_TEST}" =~ "stuff" ]]; then
        _CHECK_MIRROR=$(bash ${ffMirr} < ${ffList} 2>&1)
        _USE_MIR="${_CHECK_MIRROR}"
        [[ "${_USE_MIR}" =~ "printf" ]] && _USE_MIR="files.aegir.cc"
      else
        _USE_MIR="files.aegir.cc"
      fi
    else
      _USE_MIR="files.aegir.cc"
    fi
  else
    _USE_MIR="files.aegir.cc"
  fi
  urlDev="http://${_USE_MIR}/dev"
  urlHmr="http://${_USE_MIR}/versions/${tRee}/boa/aegir"
}

install() {
  if [ ! -d "${_LOGPTH}" ]; then
    mkdir -p ${_LOGPTH}
  fi
  _DUPLICITY_ITD=$(duplicity --version 2>&1 \
    | tr -d "\n" \
    | cut -d" " -f2 \
    | awk '{ print $1}' 2>&1)
  if [ "${_DUPLICITY_ITD}" = "${_DUPLICITY_VRN}" ] \
    && [ -e "${_LOGPTH}/boto-${_BOTO_VRN}.log" ]; then
    echo "Latest duplicity version ${_DUPLICITY_VRN} already installed"
  else
    echo "Installing duplicity dependencies..."
    cd
    find_fast_mirror_early
    if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
      && [ -e "/etc/apt/apt.conf.d" ]; then
      echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
    fi
    apt_clean_update
    aptitude purge duplicity -y
    rm -rf /usr/local/lib/python*/dist-packages/{fasteners*,duplicity*,boto*}
    mkdir -p /usr/local/lib/python2.7/dist-packages/
    mkdir -p /usr/local/lib/python3.11/dist-packages/
    rm -f /usr/local/bin/duplicity
    apt-get install librsync-dev -y
    apt-get install python-dev -y
    apt-get install python-lockfile -y
    apt-get install python-setuptools -y
    apt-get install python-monotonic -y
    apt-get install s4cmd -y
    mkdir -p /var/opt
    rm -rf /var/opt/{fasteners*,boto*,duplicity*}
    cd /var/opt
    fe="fasteners-${_FASTENERS_VRN}.tar.gz"
    curl ${crlGet} "${urlDev}/src/${fe}" -o ${fe}
    tar xzf ${fe}
    cd /var/opt/fasteners-${_FASTENERS_VRN}
    isPyth=$(which python 2>&1)
    if [ ! -x "${isPyth}" ] || [ -z "${isPyth}" ]; then
      isPyth=$(which python3 2>&1)
      if [ -x "${isPyth}" ]; then
        ln -s ${isPyth} /usr/bin/python
      fi
    fi
    python setup.py build
    python setup.py install
    echo ${_FASTENERS_VRN} > ${_LOGPTH}/fasteners-${_FASTENERS_VRN}.log
    cd /var/opt
    fe="boto-${_BOTO_VRN}.tar.gz"
    curl ${crlGet} "${urlDev}/src/${fe}" -o ${fe}
    tar xzf ${fe}
    cd /var/opt/boto-${_BOTO_VRN}
    python setup.py build
    python setup.py install
    echo ${_BOTO_VRN} > ${_LOGPTH}/boto-${_BOTO_VRN}.log
    echo "Building duplicity version ${_DUPLICITY_VRN} from sources..."
    cd /var/opt
    fe="duplicity-${_DUPLICITY_VRN}.tar.gz"
    curl ${crlGet} "${urlDev}/src/${fe}" -o ${fe}
    tar xzf ${fe}
    rm -rf /usr/local/lib/python*/dist-packages/duplicity*
    cd /var/opt/duplicity-${_DUPLICITY_VRN}
    python setup.py build
    python setup.py install
    cd
    rm -rf /var/opt/{boto*,duplicity*}
    echo "Installation complete!"
  fi
}

check_boto() {
  if [ ! -e "${_LOGPTH}/boto-${_BOTO_VRN}.log" ]; then
    echo "Upgrade to boto ${_BOTO_VRN} required..."
    install
  fi
}

if [ `ps aux | grep -v "grep" | grep --count "duplicity"` -gt "0" ]; then
  echo "The duplicity backup is already running!"
  echo "Active duplicity process detected..."
  exit 1
fi

if [ -e "/root/.barracuda.cnf" ]; then
  source /root/.barracuda.cnf
fi

if [ -z "${_AWS_KEY}" ] || [ -z "${_AWS_SEC}" ] || [ -z "${_AWS_PWD}" ]; then
  echo "

  CONFIGURATION REQUIRED!

  Add listed below four (4) required lines to your /root/.barracuda.cnf file.
  Required lines are marked with [R] and optional with [O]:

    _AWS_KEY='Your AWS Access Key ID'     ### [R] From your AWS S3 settings
    _AWS_SEC='Your AWS Secret Access Key' ### [R] From your AWS S3 settings
    _AWS_PWD='Your Secret Password'       ### [R] Generate with 'openssl rand -base64 32'
    _AWS_REG='Your AWS Region ID'         ### [R] By default 'us-east-1'
    _AWS_TTL='Your Backup Rotation'       ### [O] By default '30D'
    _AWS_FLC='Your Backup Full Cycle'     ### [O] By default '7D'
    _AWS_VLV='Your Backup Log Verbosity'  ### [O] By default '1'
    _AWS_PRG='Your Backup Progress'       ### [O] By default 'NO' -- can be YES/NO
    _AWS_EXB='Exclude Drush Archives'     ### [O] By default 'NO' -- can be YES/NO

    Supported values to use as _AWS_REG (without the # comment):

      us-east-2        # US East (Ohio)
      us-east-1        # US East (N. Virginia)
      us-west-1        # US West (N. California)
      us-west-2        # US West (Oregon)
      af-south-1       # Africa (Cape Town)
      ap-east-1        # Asia Pacific (Hong Kong)
      ap-south-1       # Asia Pacific (Mumbai)
      ap-northeast-3   # Asia Pacific (Osaka-Local)
      ap-northeast-2   # Asia Pacific (Seoul)
      ap-southeast-1   # Asia Pacific (Singapore)
      ap-southeast-2   # Asia Pacific (Sydney)
      ap-northeast-1   # Asia Pacific (Tokyo)
      ca-central-1     # Canada (Central)
      cn-north-1       # China (Beijing)
      cn-northwest-1   # China (Ningxia)
      eu-central-1     # EU (Frankfurt)
      eu-west-1        # EU (Ireland)
      eu-west-2        # EU (London)
      eu-south-1       # Europe (Milan)
      eu-west-3        # Europe (Paris)
      eu-north-1       # Europe (Stockholm)
      me-south-1       # Middle East (Bahrain)
      sa-east-1        # South America (SÃ£o Paulo)

    Source: http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region

    You have to use S3 Console at https://console.aws.amazon.com/s3/home
    (before attempting to run initial backup!) to create S3 bucket in the
    desired region with correct name as shown below:

      daily-boa-${_HST_DASH}

    While duplicity should be able to create new bucket on demand, in practice
    it almost never works due to typical delays between various AWS regions.

    Please run: 'backboa test' to make sure that the connection works.

  "
  exit 1
fi

if [ -z "${_AWS_REG}" ]; then
  _AWS_REG="us-east-1"
fi

if [ "${_AWS_REG}" = "us-east-2" ] \
  || [ "${_AWS_REG}" = "us-east-1" ] \
  || [ "${_AWS_REG}" = "us-west-1" ] \
  || [ "${_AWS_REG}" = "us-west-2" ] \
  || [ "${_AWS_REG}" = "af-south-1" ] \
  || [ "${_AWS_REG}" = "ap-east-1" ] \
  || [ "${_AWS_REG}" = "ap-south-1" ] \
  || [ "${_AWS_REG}" = "ap-northeast-3" ] \
  || [ "${_AWS_REG}" = "ap-northeast-2" ] \
  || [ "${_AWS_REG}" = "ap-southeast-1" ] \
  || [ "${_AWS_REG}" = "ap-southeast-2" ] \
  || [ "${_AWS_REG}" = "ap-northeast-1" ] \
  || [ "${_AWS_REG}" = "ca-central-1" ] \
  || [ "${_AWS_REG}" = "cn-north-1" ] \
  || [ "${_AWS_REG}" = "cn-northwest-1" ] \
  || [ "${_AWS_REG}" = "eu-central-1" ] \
  || [ "${_AWS_REG}" = "eu-west-1" ] \
  || [ "${_AWS_REG}" = "eu-west-2 " ] \
  || [ "${_AWS_REG}" = "eu-south-1 " ] \
  || [ "${_AWS_REG}" = "eu-west-3" ] \
  || [ "${_AWS_REG}" = "eu-north-1" ] \
  || [ "${_AWS_REG}" = "me-south-1" ] \
  || [ "${_AWS_REG}" = "sa-east-1" ]; then
  _GOOD_AWS_REG=YES
fi

if [ "${_AWS_REG}" = "us-east-1" ]; then
  _AWS_URL="s3-external-1.amazonaws.com"
else
  _AWS_URL="s3-${_AWS_REG}.amazonaws.com"
fi

_AWS_TTL=${_AWS_TTL//[^A-Z0-9]/}
if [ -z "${_AWS_TTL}" ]; then
  _AWS_TTL="30D"
fi

_AWS_FLC=${_AWS_FLC//[^A-Z0-9]/}
if [ -z "${_AWS_FLC}" ]; then
  _AWS_FLC="7D"
fi

if [ "${_VMFAMILY}" = "HOSTED" ] \
  && [ -e "/var/xdrago" ]; then
  _AWS_FLC="14D"
fi

_AWS_VLV=${_AWS_VLV//[^0-9]/}
if [ -z "${_AWS_VLV}" ]; then
  _AWS_VLV="1"
fi

if [ ! -z "${_AWS_EXB}" ] && [ "${_AWS_EXB}" = "YES" ]; then
  EXCLUDE="--exclude /data/conf/arch --exclude /data/disk/*/backups/*.tar.gz"
else
  EXCLUDE="--exclude /data/conf/arch"
fi

USER_INCLUDE=""
if [ -f "/root/.backboa.include" ]; then
  USER_INCLUDE="--include-filelist /root/.backboa.include"
fi

USER_EXCLUDE=""
if [ -f "/root/.backboa.exclude" ]; then
  USER_EXCLUDE="--exclude-filelist /root/.backboa.exclude"
fi

_AWS_PRG=${_AWS_PRG//[^A-Z]/}
_AWS_OPX="--s3-use-new-style"

export AWS_ACCESS_KEY_ID="${_AWS_KEY}"
export AWS_SECRET_ACCESS_KEY="${_AWS_SEC}"
export PASSPHRASE="${_AWS_PWD}"

SOURCE="/etc /var/aegir /var/www /home /data"
BUCKET="daily-boa-${_HST_DASH}"
BUCKET_DOT="daily.boa.${_HST}"
TARGET="s3://${_AWS_URL}/${BUCKET}"
LOGFILE="${_LOGPTH}/${BUCKET}.log"
_NAME="--name=daily-boa"

if [ -e "${_LOGPTH}/${BUCKET_DOT}.archive.log" ]; then
  cat ${_LOGPTH}/${BUCKET_DOT}.archive.log >> ${_LOGPTH}/${BUCKET}.archive.log
  mv ${_LOGPTH}/${BUCKET_DOT}.archive.log /var/backups/${BUCKET_DOT}.archive.log
  cat ${_LOGPTH}/${BUCKET_DOT}.randomize.cleanup.log >> ${_LOGPTH}/${BUCKET}.randomize.cleanup.log
  mv ${_LOGPTH}/${BUCKET_DOT}.randomize.cleanup.log /var/backups/${BUCKET_DOT}.randomize.cleanup.log
  apt-get clean -qq
  rm -rf /var/lib/apt/lists/*
  if [ ! -e "/etc/apt/apt.conf.d/00sandboxoff" ] \
    && [ -e "/etc/apt/apt.conf.d" ]; then
    echo "APT::Sandbox::User \"root\";" > /etc/apt/apt.conf.d/00sandboxoff
  fi
  apt_clean_update
  apt-get install python-pip -y
  pip install awscli
  aws s3 mb s3://${BUCKET} --region ${_AWS_REG}
  aws s3 sync s3://${BUCKET_DOT} s3://${BUCKET}
fi

backup_prepare() {
  if [ ! -z "${_AWS_PRG}" ] && [ "${_AWS_PRG}" = "YES" ]; then
    _AWS_OPX="--s3-use-new-style --progress"
  fi
  INCLUDE=""
  for CDIR in ${SOURCE}; do
    TMP=" --include  ${CDIR}"
    INCLUDE="${INCLUDE}${TMP}"
  done
  if [ -e "/root/.cache/duplicity" ]; then
    CacheTest=$(find /root/.cache/duplicity/* \
      -maxdepth 1 \
      -mindepth 1 \
      -type f \
      | sort 2>&1)
    if [[ "${CacheTest}" =~ "No such file or directory" ]] \
      || [ -z "${CacheTest}" ]; then
      _DO_CLEANUP=NO
    else
      _DO_CLEANUP=YES
    fi
  fi
}

monthly_cleanup() {
  if [ -e "${_LOGPTH}/${BUCKET}.randomize.cleanup.log" ]; then
    _RCL=$(cat ${_LOGPTH}/${BUCKET}.randomize.cleanup.log 2>&1)
    _RCL=$(echo -n ${_RCL} | tr -d "\n" 2>&1)
    _RCL=${_RCL//[^1-5]/}
  else
    _RCL=$((RANDOM%5+1))
    _RCL=${_RCL//[^1-5]/}
    echo ${_RCL} > ${_LOGPTH}/${BUCKET}.randomize.cleanup.log
  fi
  if [ -e "${_LOGPTH}/${BUCKET}.archive.log" ] \
    && [ ! -e "/root/.skip_duplicity_monthly_cleanup.cnf" ] \
    && [ "${_DOM}" = "${_RCL}" ] \
    && [ "${_DO_CLEANUP}" = "YES" ]; then
    if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
      n=$((RANDOM%300+8))
      echo "Waiting $n seconds on `date` before running cleanup --force" > ${LOGFILE}
      sleep $n
    fi
    echo "Running cleanup --force on `date`" >> ${LOGFILE}
    duplicity -v ${_AWS_VLV} cleanup --force ${_AWS_OPX} ${_NAME} ${TARGET}
    rm -f ${_LOGPTH}/${BUCKET}.randomize.full.log
    rm -f ${_LOGPTH}/${BUCKET}.randomize.cleanup.log
  fi
}

randomize_full() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    if [ -e "${_LOGPTH}/${BUCKET}.randomize.full.log" ]; then
      _RDW=$(cat ${_LOGPTH}/${BUCKET}.randomize.full.log 2>&1)
      _RDW=$(echo -n ${_RDW} | tr -d "\n" 2>&1)
      _RDW=${_RDW//[^1-7]/}
      _MODE="incr"
    else
      _RDW=$((RANDOM%7+1))
      _RDW=${_RDW//[^1-7]/}
      _MODE="full"
      echo ${_RDW} > ${_LOGPTH}/${BUCKET}.randomize.full.log
    fi
  else
    _RDW=7
  fi
}

set_mode() {
  if [ "${_DOW}" = "${_RDW}" ] && [ "${_AWS_FLC}" = "7D" ]; then
    if [ ! -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
      _MODE="full"
      _AWS_FLC="1M"
    fi
  else
    if [ -e "${_LOGPTH}/${BUCKET}.archive.log" ] \
      && [ "${_DO_CLEANUP}" = "YES" ]; then
      _MODE="incr"
    else
      _MODE="full"
    fi
  fi
}

run_backup() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    if [ ! -e "/root/tmp/home/" ]; then
      n=$((RANDOM%300+8))
      echo "Waiting $n seconds on `date` before running restore home 7D tmp/home" >> ${LOGFILE}
      sleep $n
      restore home 7D tmp/home >> ${LOGFILE}
    fi
    n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running ${_MODE} backup" >> ${LOGFILE}
    sleep $n
  fi
  echo "Running ${_MODE} backup on `date`" >> ${LOGFILE}
  duplicity ${_MODE} -v ${_AWS_VLV} --volsize 300 \
    --allow-source-mismatch \
    --full-if-older-than ${_AWS_FLC} \
    --asynchronous-upload ${_AWS_OPX} ${_NAME} \
    ${EXCLUDE} ${USER_EXCLUDE} ${INCLUDE} ${USER_INCLUDE} --exclude '**' / ${TARGET} >> ${LOGFILE}
}

remove_older_than() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running remove-older-than ${_AWS_TTL}" >> ${LOGFILE}
    sleep $n
  fi
  echo "Running remove-older-than on `date`" >> ${LOGFILE}
  duplicity -v ${_AWS_VLV} remove-older-than ${_AWS_TTL} \
    --force ${_AWS_OPX} ${_NAME} ${TARGET} >> ${LOGFILE}
}

collection_status() {
  if [ -e "/root/.randomize_duplicity_full_backup_day.cnf" ]; then
    n=$((RANDOM%300+8))
    echo "Waiting $n seconds on `date` before running collection-status" >> ${LOGFILE}
    sleep $n
  fi
  echo "Running collection-status on `date`" >> ${LOGFILE}
  duplicity -v ${_AWS_VLV} collection-status ${_AWS_OPX} ${_NAME} ${TARGET} >> ${LOGFILE}
}

backup() {
  backup_prepare
  monthly_cleanup
  randomize_full
  set_mode
  run_backup
  if [ -e "${_LOGPTH}/${BUCKET}.archive.log" ] \
    && [ "${_DOW}" = "${_RDW}" ] \
    && [ "${_DO_CLEANUP}" = "YES" ]; then
    remove_older_than
    collection_status
  fi
  if [ -n "${_MY_EMAIL}" ] && [ "${_AWS_VLV}" -lt "3" ]; then
    echo "Sending email report on `date`" >> ${LOGFILE}
    mail -s "Daily backup: ${_MODE} ${_HST} $(date 2>&1)" ${_MY_EMAIL} < ${LOGFILE}
  fi
  cat ${LOGFILE} >> ${_LOGPTH}/${BUCKET}.archive.log
  rm -f ${LOGFILE}
}

conn_test() {
  if [ $# = 1 ]; then
    BUCKET="daily-boa-$1"
    TARGET="s3://${_AWS_URL}/${BUCKET}"
  fi
  echo "Running AWS connection test, please wait..."
  ConnTest=$(duplicity -v 2 cleanup --dry-run \
    --timeout 1 ${_AWS_OPX} ${_NAME} ${TARGET} 2>&1)
  ### echo ConnTest is STR ${ConnTest} END
  if [[ "${ConnTest}" =~ "No connection to backend" ]] \
    || [[ "${ConnTest}" =~ "IllegalLocationConstraintException" ]]; then
    echo
    echo "  Sorry, I can't connect to ${TARGET}"
    echo "  Please check if the bucket has expected name: ${BUCKET}"
    echo "  This bucket must already exist in the ${_AWS_REG} AWS region"
    echo "  http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region"
    echo "  Bye"
    echo
    exit 1
  else
    echo "OK, I can connect to ${TARGET}"
  fi
}

status() {
  duplicity -v ${_AWS_VLV} collection-status ${_AWS_OPX} ${_NAME} ${TARGET}
}

cleanup() {
  duplicity -v ${_AWS_VLV} cleanup --force ${_AWS_OPX} ${_NAME} ${TARGET}
  duplicity -v ${_AWS_VLV} collection-status ${_AWS_OPX} ${_NAME} ${TARGET}
}

list() {
  duplicity -v ${_AWS_VLV} list-current-files ${_AWS_OPX} ${_NAME} ${TARGET}
}

restore() {
  if [ $# = 2 ]; then
    duplicity -v ${_AWS_VLV} restore \
      --file-to-restore $1 ${_AWS_OPX} ${_NAME} ${TARGET} $2
  else
    duplicity -v ${_AWS_VLV} restore \
      --file-to-restore $1 --time $2 ${_AWS_OPX} ${_NAME} ${TARGET} $3
  fi
}

retrieve() {
  if [ $# = 3 ]; then
    _HST_DASH=$(echo -n $3 | tr . - 2>&1)
    BUCKET="daily-boa-${_HST_DASH}"
    TARGET="s3://${_AWS_URL}/${BUCKET}"
    duplicity restore --file-to-restore $1 ${_AWS_OPX} ${_NAME} ${TARGET} $2
  elif [ $# = 4 ]; then
    _HST_DASH=$(echo -n $4 | tr . - 2>&1)
    BUCKET="daily-boa-${_HST_DASH}"
    TARGET="s3://${_AWS_URL}/${BUCKET}"
    duplicity restore --file-to-restore $1 --time $2 ${_AWS_OPX} ${_NAME} ${TARGET} $3
  fi
}

if [ "$1" = "backup" ]; then
  if test -f /var/run/${_HST}_backup.pid ; then
    touch ${_LOGPTH}/wait_${_HST}_backup.log
    echo "The duplicity backup is running already?"
    echo "Existing /var/run/${_HST}_backup.pid found..."
    echo "But no active duplicity process detected..."
    exit 1
  else
    touch /var/run/${_HST}_backup.pid
    echo "The duplicity backup is starting now..."
    check_boto
    backup
    echo "The duplicity backup is complete!"
    touch ${_LOGPTH}/run_${_HST}_backup.log
    rm -f /var/run/${_HST}_backup.pid
  fi
elif [ "$1" = "install" ]; then
  install
elif [ "$1" = "cleanup" ]; then
  cleanup
elif [ "$1" = "list" ]; then
  list
elif [ "$1" = "restore" ]; then
  if [ $# = 3 ]; then
    restore $2 $3
  else
    restore $2 $3 $4
  fi
elif [ "$1" = "retrieve" ]; then
  if [ $# = 4 ]; then
    retrieve $2 $3 $4
  elif [ $# = 5 ]; then
    retrieve $2 $3 $4 $5
  else
    echo "You have to specify also hostname of the backed up system"
    exit 1
  fi
elif [ "$1" = "status" ]; then
  check_boto
  status
elif [ "$1" = "test" ]; then
  conn_test
else
  echo "

  INSTALLATION:

  $ backboa install

  USAGE:

  $ backboa backup
  $ backboa cleanup
  $ backboa list
  $ backboa status
  $ backboa test
  $ backboa restore file [time] destination
  $ backboa retrieve file [time] destination hostname

  RESTORE EXAMPLES:

  Note: Be careful while restoring not to prepend a slash to the path!

  Restoring a single file to tmp/
  $ backboa restore data/disk/o1/backups/foo.tar.gz tmp/foo.tar.gz

  Restoring an older version of a directory to tmp/ - interval or full date
  $ backboa restore data/disk/o1/backups 7D8h8s tmp/backups
  $ backboa restore data/disk/o1/backups 2014/11/11 tmp/backups

  Restoring data on a different server
  $ backboa retrieve data/disk/o1/backups/foo.tar.gz tmp/foo.tar.gz srv.foo.bar
  $ backboa retrieve data/disk/o1/backups 2014/11/11 tmp/backups srv.foo.bar

  Note: The srv.foo.bar is a hostname of the BOA system backed up before.
        In the 'retrieve' mode it will use the _AWS_* variables configured
        in the current system /root/.barracuda.cnf file - so make sure to edit
        this file to set/replace temporarily all four required _AWS_* variables
        used originally on the host you are retrieving data from! You should
        keep them secret and manage in your offline password manager app.

  "
  exit 1
fi

export AWS_ACCESS_KEY_ID=
export AWS_SECRET_ACCESS_KEY=
export PASSPHRASE=

exit 0
